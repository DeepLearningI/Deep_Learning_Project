Text Generation with LSTM
This project generates text using a character-level LSTM neural network trained on a collection of books from Project Gutenberg. The training data is preprocessed using NLTK and tokenized using Keras. The model is implemented in TensorFlow 2.0.

Dataset
The training data consists of a collection of books obtained from Project Gutenberg. The books were preprocessed to remove unnecessary metadata and concatenated to form a single text file.

Dependencies
The following Python packages are required to run this project:

requests
tensorflow
spacy
nltk
numpy


